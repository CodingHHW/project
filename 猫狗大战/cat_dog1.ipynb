{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-05T10:39:07.371081",
     "start_time": "2017-03-05T10:39:07.349547"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import ticker\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Convolution2D, MaxPooling2D, Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-05T10:39:12.249592",
     "start_time": "2017-03-05T10:39:12.025313"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = '/Users/hehongwei/datas/Cat_Dog/train/'\n",
    "\n",
    "train_images = [TRAIN_DIR + i for i in os.listdir(TRAIN_DIR)]\n",
    "train_images = train_images[1:]\n",
    "dogs = [i for i in train_images if 'dog' in i]\n",
    "cats = [i for i in train_images if 'cat' in i]\n",
    "# 以上已经提取了dog的路径和cat的路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-05T10:39:13.930170",
     "start_time": "2017-03-05T10:39:13.925646"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n",
      "12500\n"
     ]
    }
   ],
   "source": [
    "print len(dogs)\n",
    "print len(cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提取1000张dog，1000张cat作为训练集，提取1000张dog，1000张cat作为验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-05T10:39:18.252924",
     "start_time": "2017-03-05T10:39:18.240964"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dogs = dogs[0:1000]\n",
    "train_cats = cats[0:1000]\n",
    "# 做好验证机数据和标签\n",
    "\n",
    "V_cross_dogs = dogs[1000:2000]\n",
    "V_cross_cats = cats[1000:2000]\n",
    "V_cross_images = V_cross_dogs + V_cross_cats\n",
    "random.shuffle(V_cross_images)\n",
    "V_labels = []\n",
    "for i in V_cross_images:\n",
    "    if 'cat' in i:\n",
    "        V_labels.append(0)\n",
    "    if 'dog' in i:\n",
    "        V_labels.append(1)\n",
    "# 上面做好了验证集的数据和标签V_cross_images和V_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将2000个训练集数据进行数据提升,提升后的数据保存在/Users/hehongwei/datas/Cat_Dog/preview/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-05T11:15:35.923582",
     "start_time": "2017-03-05T10:41:37.812242"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "for dog in train_dogs:\n",
    "    img = cv2.imread(dog)\n",
    "    x = img_to_array(img)\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1, save_to_dir='/Users/hehongwei/datas/Cat_Dog/preview/', save_prefix='dog', save_format='jpeg'):\n",
    "        i += 1\n",
    "        if i > 20:\n",
    "            break\n",
    "for cat in train_cats:\n",
    "    img = cv2.imread(cat)\n",
    "    x = img_to_array(img)\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1, save_to_dir='/Users/hehongwei/datas/Cat_Dog/preview/', save_prefix='cat', save_format='jpeg'):\n",
    "        i += 1\n",
    "        if i > 20:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-04T10:50:05.034036",
     "start_time": "2017-03-04T10:50:05.027747"
    },
    "collapsed": true
   },
   "source": [
    "对提升后的数据进行训练数据的预处理，做好数据和标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-05T12:49:39.946987",
     "start_time": "2017-03-05T12:49:39.861444"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN_IMAGES_DIR = '/Users/hehongwei/datas/Cat_Dog/preview/'\n",
    "train_images = [TRAIN_IMAGES_DIR + i for i in os.listdir(TRAIN_IMAGES_DIR)]\n",
    "train_images = train_images[1:]\n",
    "random.shuffle(train_images)\n",
    "y_labels = []\n",
    "for i in train_images:\n",
    "    if 'cat' in i:\n",
    "        y_labels.append(0)\n",
    "    if 'dog' in i:\n",
    "        y_labels.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建立神经网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-05T12:49:49.398331",
     "start_time": "2017-03-05T12:49:48.960965"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# 输入数据要处理为3*150*150\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(3, 150, 150)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-05T12:49:53.626680",
     "start_time": "2017-03-05T12:49:53.615759"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 处理训练数据\n",
    "ROWS = 150\n",
    "COLS = 150\n",
    "CHANNELS = 3\n",
    "\n",
    "def read_image(file_path):\n",
    "    img = cv2.imread(file_path)\n",
    "    return cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n",
    "def prep_data(images):\n",
    "    count = len(images)\n",
    "    data = np.ndarray([count, CHANNELS, ROWS, COLS])\n",
    "    for i, image_file in enumerate(images):\n",
    "        image = read_image(image_file)\n",
    "        data[i] = image.T\n",
    "        if i % 250 == 0:\n",
    "            print('Processed {} of {}'.format(i, count))\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-05T12:51:58.613554",
     "start_time": "2017-03-05T12:49:59.710876"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 of 17557\n",
      "Processed 250 of 17557\n",
      "Processed 500 of 17557\n",
      "Processed 750 of 17557\n",
      "Processed 1000 of 17557\n",
      "Processed 1250 of 17557\n",
      "Processed 1500 of 17557\n",
      "Processed 1750 of 17557\n",
      "Processed 2000 of 17557\n",
      "Processed 2250 of 17557\n",
      "Processed 2500 of 17557\n",
      "Processed 2750 of 17557\n",
      "Processed 3000 of 17557\n",
      "Processed 3250 of 17557\n",
      "Processed 3500 of 17557\n",
      "Processed 3750 of 17557\n",
      "Processed 4000 of 17557\n",
      "Processed 4250 of 17557\n",
      "Processed 4500 of 17557\n",
      "Processed 4750 of 17557\n",
      "Processed 5000 of 17557\n",
      "Processed 5250 of 17557\n",
      "Processed 5500 of 17557\n",
      "Processed 5750 of 17557\n",
      "Processed 6000 of 17557\n",
      "Processed 6250 of 17557\n",
      "Processed 6500 of 17557\n",
      "Processed 6750 of 17557\n",
      "Processed 7000 of 17557\n",
      "Processed 7250 of 17557\n",
      "Processed 7500 of 17557\n",
      "Processed 7750 of 17557\n",
      "Processed 8000 of 17557\n",
      "Processed 8250 of 17557\n",
      "Processed 8500 of 17557\n",
      "Processed 8750 of 17557\n",
      "Processed 9000 of 17557\n",
      "Processed 9250 of 17557\n",
      "Processed 9500 of 17557\n",
      "Processed 9750 of 17557\n",
      "Processed 10000 of 17557\n",
      "Processed 10250 of 17557\n",
      "Processed 10500 of 17557\n",
      "Processed 10750 of 17557\n",
      "Processed 11000 of 17557\n",
      "Processed 11250 of 17557\n",
      "Processed 11500 of 17557\n",
      "Processed 11750 of 17557\n",
      "Processed 12000 of 17557\n",
      "Processed 12250 of 17557\n",
      "Processed 12500 of 17557\n",
      "Processed 12750 of 17557\n",
      "Processed 13000 of 17557\n",
      "Processed 13250 of 17557\n",
      "Processed 13500 of 17557\n",
      "Processed 13750 of 17557\n",
      "Processed 14000 of 17557\n",
      "Processed 14250 of 17557\n",
      "Processed 14500 of 17557\n",
      "Processed 14750 of 17557\n",
      "Processed 15000 of 17557\n",
      "Processed 15250 of 17557\n",
      "Processed 15500 of 17557\n",
      "Processed 15750 of 17557\n",
      "Processed 16000 of 17557\n",
      "Processed 16250 of 17557\n",
      "Processed 16500 of 17557\n",
      "Processed 16750 of 17557\n",
      "Processed 17000 of 17557\n",
      "Processed 17250 of 17557\n",
      "Processed 17500 of 17557\n"
     ]
    }
   ],
   "source": [
    "train_data = prep_data(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-05T15:20:25.460140",
     "start_time": "2017-03-05T12:53:03.264961"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13167 samples, validate on 4390 samples\n",
      "Epoch 1/15\n",
      "13167/13167 [==============================] - 548s - loss: 8.0416 - acc: 0.5009 - val_loss: 8.0884 - val_acc: 0.4982\n",
      "Epoch 2/15\n",
      "13167/13167 [==============================] - 571s - loss: 8.0413 - acc: 0.5011 - val_loss: 8.0884 - val_acc: 0.4982\n",
      "Epoch 3/15\n",
      "13167/13167 [==============================] - 559s - loss: 8.0413 - acc: 0.5011 - val_loss: 8.0884 - val_acc: 0.4982\n",
      "Epoch 4/15\n",
      "13167/13167 [==============================] - 590s - loss: 8.0413 - acc: 0.5011 - val_loss: 8.0884 - val_acc: 0.4982\n",
      "Epoch 5/15\n",
      "13167/13167 [==============================] - 591s - loss: 8.0413 - acc: 0.5011 - val_loss: 8.0884 - val_acc: 0.4982\n",
      "Epoch 6/15\n",
      "13167/13167 [==============================] - 613s - loss: 8.0413 - acc: 0.5011 - val_loss: 8.0884 - val_acc: 0.4982\n",
      "Epoch 7/15\n",
      "13167/13167 [==============================] - 598s - loss: 8.0413 - acc: 0.5011 - val_loss: 8.0884 - val_acc: 0.4982\n",
      "Epoch 8/15\n",
      "13167/13167 [==============================] - 606s - loss: 8.0413 - acc: 0.5011 - val_loss: 8.0884 - val_acc: 0.4982\n",
      "Epoch 9/15\n",
      "13167/13167 [==============================] - 587s - loss: 8.0413 - acc: 0.5011 - val_loss: 8.0884 - val_acc: 0.4982\n",
      "Epoch 10/15\n",
      "13167/13167 [==============================] - 580s - loss: 8.0413 - acc: 0.5011 - val_loss: 8.0884 - val_acc: 0.4982\n",
      "Epoch 11/15\n",
      "13167/13167 [==============================] - 574s - loss: 8.0413 - acc: 0.5011 - val_loss: 8.0884 - val_acc: 0.4982\n",
      "Epoch 12/15\n",
      "13167/13167 [==============================] - 582s - loss: 8.0413 - acc: 0.5011 - val_loss: 8.0884 - val_acc: 0.4982\n",
      "Epoch 13/15\n",
      "13167/13167 [==============================] - 600s - loss: 8.0413 - acc: 0.5011 - val_loss: 8.0884 - val_acc: 0.4982\n",
      "Epoch 14/15\n",
      "13167/13167 [==============================] - 604s - loss: 8.0413 - acc: 0.5011 - val_loss: 8.0884 - val_acc: 0.4982\n",
      "Epoch 15/15\n",
      "13167/13167 [==============================] - 625s - loss: 8.0413 - acc: 0.5011 - val_loss: 8.0884 - val_acc: 0.4982\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 15\n",
    "batch_size = 16\n",
    "\n",
    "hist = model.fit(train_data, y_labels, validation_split=0.25,\n",
    "                 nb_epoch=nb_epoch, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-05T15:24:30.283060",
     "start_time": "2017-03-05T15:20:25.754840"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17557/17557 [==============================] - 244s   \n"
     ]
    }
   ],
   "source": [
    "train_scores = model.evaluate(train_data, y_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-05T15:25:08.899640",
     "start_time": "2017-03-05T15:25:08.882337"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.0530805511179118, 0.50037022270489273]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-05T15:24:44.634908",
     "start_time": "2017-03-05T15:24:30.567455"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 of 2000\n",
      "Processed 250 of 2000\n",
      "Processed 500 of 2000\n",
      "Processed 750 of 2000\n",
      "Processed 1000 of 2000\n",
      "Processed 1250 of 2000\n",
      "Processed 1500 of 2000\n",
      "Processed 1750 of 2000\n"
     ]
    }
   ],
   "source": [
    "# 处理验证数据\n",
    "V_cross_data = prep_data(V_cross_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-05T15:24:44.836410",
     "start_time": "2017-03-05T15:24:44.767627"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 3, 150, 150)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_cross_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-05T15:25:08.771675",
     "start_time": "2017-03-05T15:24:45.321027"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 23s    \n"
     ]
    }
   ],
   "source": [
    "V_cross_scores = model.evaluate(V_cross_data, V_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-05T15:25:08.989734",
     "start_time": "2017-03-05T15:25:08.982546"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.0590477905273445, 0.5]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_cross_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
